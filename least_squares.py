# -*- coding: utf-8 -*-
"""Least Squares.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A_8fBJIA7zQGKVDxV5EEioPHXAUnudXY
"""

#Import the libraries
import numpy as np
import pandas as pd

"""Dataset from : https://www.kaggle.com/grubenm/austin-weather
Project refrences: https://www.youtube.com/watch?time_continue=446&v=Qa_FI92_qo8&feature=emb_title
"""

#Read the csv file
data = pd.read_csv("austin_weather.csv")
#replace "-" values with 0
data = data.replace('-', 0)
data.head()

"""The goal of this project is to perform least square linear regression using matrices.

The least square regression line is defined as:
$f(x) = b + mx$
where $b$ is the y-intercept and $m$ is the slope of the line.

The equation minimizes the sum of squared errors, which are the errors in using the regression function $f(x)$ to estimate true $y$ values.

# Matrix Equation:
$Y = XA + E.$

> Solve this equation for A



# Solution to least square regression equation:
$A = (X^T X)^-1  X^T Y$

# The sum of squared errors is:
$SSE = E^T E$
"""

X = data.iloc[:,[5]].values

Y = data.iloc[:,[2]].values

"""Y is the matrix $Y$ which containts the given $y$ values. X which is matrix $X$ has two columns: A column of 1's and a column of given $x$ values. 
Matrix $A$ contains the y-intercept and slope. Matrix $E$ contains all of the errors. 
The matrix $Y$ contains the average temperature in F whereas the matrix X contains the Average dew points in F for the corresponding temperature. The prediction of average temperature will be based on the dew point.
"""

#converting X from string to integers
X = X.astype(str).astype(int)

#Adding a column of all 1's in Matrix X 
Z = np.ones((1319,1), dtype=int)
Z.shape
XX = np.append(Z,X, axis = 1)
#XX.shape

"""Using $Y = XA + E.$ we need to find $X$ using $A = (X^T X)^-1  X^T Y$

Step 1:
$(X^T X)$
"""

#Step 1
# (X^T) X
# OR X transpose * X
XT = XX.T
XT
product_xTx = np.matmul(XT, XX)
#print (data.dtypes)

"""Step 2: $(X^TX)^-1$"""

#Step 2
#Inverse of (xTx)
inverse = np.linalg.inv(product_xTx)

"""Step 3: $X^T Y$"""

# Step 3
# Product of transpose of X and Y 
xTy = np.matmul(XT, Y)

"""Step 4: $A = (X^T X)^-1  X^T Y$"""

# Step 4
#Product of step 2 and 3
A = np.matmul(inverse, xTy)
A

# 6.89698352e+01 is (b) y-intercept of regression line whereas 2.51322494e-02 is slope of regression line.
A[0]

"""Step 4 gives us 2x1 matrix $A$ where matrix element $A11$ is $b$ and $A21$ is $m$

The step below is to calculate $f(x) = b + mx$
>>$f(x) = 27.59 + 0.76 x$

Now to find the Sum of Squared Errors $SSE$ we need to find $f(x)$
"""

#f(x)
fx = A[0] + (A[1]*X)

"""The matrix $E$ is the error matrix which is acquired by subtracting $y$ from $f(x)$

>> $ e = y - f(x)$
"""

#Matrix E
matrix_e = np.subtract(Y, fx)

"""Sum of Squared Errors $SSE = E^TE$"""

#SSE 
ET = matrix_e.T
SSE = np.matmul(ET, matrix_e)
SSE



"""Using the equation $f(x) = b + mx$ we can predict the average temperature in Austin based on the average dew point. The average weather in Austin for 75F dew point is shown below:"""

dew_point = 75
prediction = A[0] + (A[1] * dew_point)
prediction = prediction.astype(int)
print("The average temperature in Austin for", dew_point, "dew point is: ", prediction, "F")